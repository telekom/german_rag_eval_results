{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_files = glob.glob(\"./german_rag_eval/**/*.json\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_eval_result(filename: str):\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    result = {}\n",
    "    model_name = data[\"config_general\"][\"model_name\"]\n",
    "    result[\"model_name\"] = model_name\n",
    "    eval_results = data[\"results\"]\n",
    "    for k, v in eval_results.items():\n",
    "        if \"_average\" in k:\n",
    "            continue\n",
    "        k = k.replace(\"community|german_rag_eval:\", \"\")\n",
    "        if \"|\" in k:\n",
    "            k = k[:-2]\n",
    "        result[f\"{k}_acc\"] = v[\"acc\"]\n",
    "        result[f\"{k}_acc_stderr\"] = v[\"acc_stderr\"]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = []\n",
    "\n",
    "for eval_result_file in eval_result_files:\n",
    "    eval_results.append(read_eval_result(eval_result_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>choose_context_by_question_acc</th>\n",
       "      <th>choose_context_by_question_acc_stderr</th>\n",
       "      <th>choose_question_by_context_acc</th>\n",
       "      <th>choose_question_by_context_acc_stderr</th>\n",
       "      <th>context_question_match_acc</th>\n",
       "      <th>context_question_match_acc_stderr</th>\n",
       "      <th>question_answer_match_acc</th>\n",
       "      <th>question_answer_match_acc_stderr</th>\n",
       "      <th>all_acc</th>\n",
       "      <th>all_acc_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.97500</td>\n",
       "      <td>0.004521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mistralai/Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.97100</td>\n",
       "      <td>0.004796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta-llama/Meta-Llama-3-70B-Instruct</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.96500</td>\n",
       "      <td>0.004925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>microsoft/Phi-3-mini-4k-instruct</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.94350</td>\n",
       "      <td>0.006128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.91000</td>\n",
       "      <td>0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.009336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DiscoResearch/DiscoLM_German_7b_v1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.86425</td>\n",
       "      <td>0.008851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>occiglot/occiglot-7b-de-en-instruct</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.79225</td>\n",
       "      <td>0.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>occiglot/occiglot-7b-eu5-instruct</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.77625</td>\n",
       "      <td>0.011567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LeoLM/leo-mistral-hessianai-7b-chat</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>0.76725</td>\n",
       "      <td>0.011885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>occiglot/occiglot-7b-de-en</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DiscoResearch/Llama3_DiscoLM_German_8b_v0.1_ex...</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.014206</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.015537</td>\n",
       "      <td>0.48200</td>\n",
       "      <td>0.014491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>occiglot/occiglot-7b-eu5</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.015605</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>0.47725</td>\n",
       "      <td>0.015521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name  \\\n",
       "1     VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct   \n",
       "0    VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct   \n",
       "2                mistralai/Mixtral-8x7B-Instruct-v0.1   \n",
       "4                meta-llama/Meta-Llama-3-70B-Instruct   \n",
       "7                    microsoft/Phi-3-mini-4k-instruct   \n",
       "11     VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct   \n",
       "3                 meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "6                  DiscoResearch/DiscoLM_German_7b_v1   \n",
       "13                occiglot/occiglot-7b-de-en-instruct   \n",
       "8                   occiglot/occiglot-7b-eu5-instruct   \n",
       "5                 LeoLM/leo-mistral-hessianai-7b-chat   \n",
       "12                         occiglot/occiglot-7b-de-en   \n",
       "9   DiscoResearch/Llama3_DiscoLM_German_8b_v0.1_ex...   \n",
       "10                           occiglot/occiglot-7b-eu5   \n",
       "\n",
       "    choose_context_by_question_acc  choose_context_by_question_acc_stderr  \\\n",
       "1                            0.998                               0.001414   \n",
       "0                            0.953                               0.006696   \n",
       "2                            0.940                               0.007514   \n",
       "4                            0.940                               0.007514   \n",
       "7                            0.847                               0.011390   \n",
       "11                           0.928                               0.008178   \n",
       "3                            0.725                               0.014127   \n",
       "6                            0.625                               0.015317   \n",
       "13                           0.343                               0.015019   \n",
       "8                            0.722                               0.014175   \n",
       "5                            0.865                               0.010812   \n",
       "12                           0.453                               0.015749   \n",
       "9                            0.303                               0.014540   \n",
       "10                           0.327                               0.014842   \n",
       "\n",
       "    choose_question_by_context_acc  choose_question_by_context_acc_stderr  \\\n",
       "1                            1.000                               0.000000   \n",
       "0                            0.998                               0.001414   \n",
       "2                            0.998                               0.001414   \n",
       "4                            1.000                               0.000000   \n",
       "7                            0.998                               0.001414   \n",
       "11                           0.824                               0.012049   \n",
       "3                            0.855                               0.011140   \n",
       "6                            0.991                               0.002988   \n",
       "13                           0.994                               0.002443   \n",
       "8                            0.982                               0.004206   \n",
       "5                            0.949                               0.006960   \n",
       "12                           0.698                               0.014526   \n",
       "9                            0.280                               0.014206   \n",
       "10                           0.582                               0.015605   \n",
       "\n",
       "    context_question_match_acc  context_question_match_acc_stderr  \\\n",
       "1                        0.973                           0.005128   \n",
       "0                        0.975                           0.004940   \n",
       "2                        0.973                           0.005128   \n",
       "4                        0.974                           0.005035   \n",
       "7                        0.965                           0.005815   \n",
       "11                       0.982                           0.004206   \n",
       "3                        0.977                           0.004743   \n",
       "6                        0.914                           0.008870   \n",
       "13                       0.863                           0.010879   \n",
       "8                        0.587                           0.015578   \n",
       "5                        0.735                           0.013963   \n",
       "12                       0.501                           0.015819   \n",
       "9                        0.751                           0.013682   \n",
       "10                       0.500                           0.015819   \n",
       "\n",
       "    question_answer_match_acc  question_answer_match_acc_stderr  all_acc  \\\n",
       "1                       0.949                          0.006960  0.98000   \n",
       "0                       0.974                          0.005035  0.97500   \n",
       "2                       0.973                          0.005128  0.97100   \n",
       "4                       0.946                          0.007151  0.96500   \n",
       "7                       0.964                          0.005894  0.94350   \n",
       "11                      0.906                          0.009233  0.91000   \n",
       "3                       0.943                          0.007335  0.87500   \n",
       "6                       0.927                          0.008230  0.86425   \n",
       "13                      0.969                          0.005484  0.79225   \n",
       "8                       0.814                          0.012311  0.77625   \n",
       "5                       0.520                          0.015807  0.76725   \n",
       "12                      0.500                          0.015819  0.53800   \n",
       "9                       0.594                          0.015537  0.48200   \n",
       "10                      0.500                          0.015819  0.47725   \n",
       "\n",
       "    all_acc_stderr  \n",
       "1         0.003376  \n",
       "0         0.004521  \n",
       "2         0.004796  \n",
       "4         0.004925  \n",
       "7         0.006128  \n",
       "11        0.008417  \n",
       "3         0.009336  \n",
       "6         0.008851  \n",
       "13        0.008456  \n",
       "8         0.011567  \n",
       "5         0.011885  \n",
       "12        0.015478  \n",
       "9         0.014491  \n",
       "10        0.015521  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(eval_results)\n",
    "df.sort_values(\"all_acc\", ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if column.endswith(\"_stderr\") and column != \"all_acc_stderr\":\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "df.columns = [c.replace(\"_\", \" \") for c in df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model name                                               |   choose context by question acc |   choose question by context acc |   context question match acc |   question answer match acc |   all acc |   all acc stderr |\n",
      "|:---------------------------------------------------------|---------------------------------:|---------------------------------:|-----------------------------:|----------------------------:|----------:|-----------------:|\n",
      "| VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct          |                            0.998 |                            1     |                        0.973 |                       0.949 |   0.98    |       0.0033755  |\n",
      "| VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct         |                            0.953 |                            0.998 |                        0.975 |                       0.974 |   0.975   |       0.00452096 |\n",
      "| mistralai/Mixtral-8x7B-Instruct-v0.1                     |                            0.94  |                            0.998 |                        0.973 |                       0.973 |   0.971   |       0.00479586 |\n",
      "| meta-llama/Meta-Llama-3-70B-Instruct                     |                            0.94  |                            1     |                        0.974 |                       0.946 |   0.965   |       0.00492486 |\n",
      "| microsoft/Phi-3-mini-4k-instruct                         |                            0.847 |                            0.998 |                        0.965 |                       0.964 |   0.9435  |       0.00612787 |\n",
      "| VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct           |                            0.928 |                            0.824 |                        0.982 |                       0.906 |   0.91    |       0.00841656 |\n",
      "| meta-llama/Meta-Llama-3-8B-Instruct                      |                            0.725 |                            0.855 |                        0.977 |                       0.943 |   0.875   |       0.00933624 |\n",
      "| DiscoResearch/DiscoLM_German_7b_v1                       |                            0.625 |                            0.991 |                        0.914 |                       0.927 |   0.86425 |       0.0088514  |\n",
      "| occiglot/occiglot-7b-de-en-instruct                      |                            0.343 |                            0.994 |                        0.863 |                       0.969 |   0.79225 |       0.00845623 |\n",
      "| occiglot/occiglot-7b-eu5-instruct                        |                            0.722 |                            0.982 |                        0.587 |                       0.814 |   0.77625 |       0.0115674  |\n",
      "| LeoLM/leo-mistral-hessianai-7b-chat                      |                            0.865 |                            0.949 |                        0.735 |                       0.52  |   0.76725 |       0.0118855  |\n",
      "| occiglot/occiglot-7b-de-en                               |                            0.453 |                            0.698 |                        0.501 |                       0.5   |   0.538   |       0.0154785  |\n",
      "| DiscoResearch/Llama3_DiscoLM_German_8b_v0.1_experimental |                            0.303 |                            0.28  |                        0.751 |                       0.594 |   0.482   |       0.0144911  |\n",
      "| occiglot/occiglot-7b-eu5                                 |                            0.327 |                            0.582 |                        0.5   |                       0.5   |   0.47725 |       0.0155215  |\n"
     ]
    }
   ],
   "source": [
    "print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
